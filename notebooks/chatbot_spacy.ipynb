{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wgsbg31Uc_Bm",
    "outputId": "82f7356b-78ca-484f-c2e9-34208411591c"
   },
   "outputs": [],
   "source": [
    "!pip install langdetect\n",
    "!python -m spacy download el_core_news_sm\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import re\n",
    "import random\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from langdetect import detect\n",
    "# Download NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 909
    },
    "id": "5g1TVB4ku9qp",
    "outputId": "a3d5d758-47e6-4268-a340-ab2e05f8b8c5"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('C:/Users/Katerina/Documents/Chatbot/Customer Utterances.csv')\n",
    "\n",
    "\n",
    "query_column = \"Utterance\"\n",
    "queries = df[query_column].dropna().tolist()  # Convert to list and remove NaN values\n",
    "\n",
    "\n",
    "# Load Greek SpaCy model\n",
    "import spacy\n",
    "nlp = spacy.load(\"el_core_news_sm\")\n",
    "\n",
    "  # Load stopwords\n",
    "english_stopwords = set(stopwords.words('english'))\n",
    "greek_stopwords = set(stopwords.words('greek'))\n",
    "custom_stopwords = set(['θέλω','έχω',\n",
    "    'και', 'να', 'το', 'μου', 'του', 'της', 'εγω', 'ένα', 'σε', 'με', 'για','κάνω', 'εγώ',\n",
    "    'θα', 'απο', 'αυτό', 'αυτή', 'αυτο', 'ότι', 'πως', 'πολύ', 'εδώ', 'εκεί', 'είμαι','ακόμη', 'αυτές', 'στο','στις', 'στους','στα','στο','στη','δικό', 'δικού',\n",
    "'δικός','εσάς', 'την', 'τα', 'είναι','μια', 'μία','έχει', 'είχαμε', 'είχα', 'έχουμε', 'έχετε','ήθελα','κάνετε', 'κάνει', 'έκανα','κάποιον', 'κάποιο', 'κάποιες','λέω', 'δω', 'μπω', 'πω', 'πείτε','τους', 'σας', 'μας','μπορείτε', 'μπορούσατε', 'μπορούσα', 'μπορεί',\n",
    "'τη', 'τους', 'τo', 'η', 'οι', 'τα', 'το', 'την', 'των', 'τις', 'τον','όλων', 'όλης', 'όλο', 'όλοι', 'όλους','οποίο','ποιους', 'ποια', 'ποιο', 'ποιες','ποιον','πόση','πόσες','πόση', 'πόσα','πόσα','σ',\"σε\"]) \n",
    "custom_stopwords = {word.lower() for word in custom_stopwords}\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join([char for char in text if char.isalnum() or char == ' '])  # punctuation\n",
    "    # Process text using SpaCy\n",
    "    doc = nlp(text)\n",
    "    # Apply lemmatization and stopword removal (using the lemmatized form)\n",
    "    text = ' '.join([token.lemma_ for token in doc if token.lemma_.lower() not in english_stopwords\n",
    "                     and token.lemma_.lower() not in greek_stopwords\n",
    "                     and token.lemma_.lower() not in custom_stopwords])\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ZuFmK7H0e59",
    "outputId": "26a3b420-90f0-47d6-c384-bb45bc0c6f35"
   },
   "outputs": [],
   "source": [
    "data = [preprocess_text(text) for text in queries]\n",
    "df[\"processed_queries\"] = data\n",
    "df.to_csv(\"processed_queries.csv\", index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "Nj1hAXUP1182",
    "outputId": "7573bacc-d175-4beb-96d5-86f1279e36b5"
   },
   "outputs": [],
   "source": [
    "# Load Sentence-BERT model\n",
    "model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')\n",
    "\n",
    "# Generate sentence embeddings\n",
    "sentence_embeddings = model.encode(data)\n",
    "\n",
    "# optimal number of clusters\n",
    "inertia = []\n",
    "for k in range(1, 30):  # Test 1 to 20 clusters\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(sentence_embeddings)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Elbow plot\n",
    "plt.plot(range(1, 30), inertia, marker='o')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "_3a5xt6tG-aw",
    "outputId": "7f239c3f-0efa-427d-b1e7-6c1147a335f8"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Test different numbers of clusters\n",
    "silhouette_scores = []\n",
    "for k in range(2, 30):  # Start from 2 clusters\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(sentence_embeddings)\n",
    "    score = silhouette_score(sentence_embeddings, kmeans.labels_)\n",
    "    silhouette_scores.append(score)\n",
    "\n",
    "# Plot the silhouette scores\n",
    "plt.plot(range(2, 30), silhouette_scores, marker='o')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Method')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6TP8yXbQ2tTh",
    "outputId": "02cbe5c3-62e1-4994-c25c-c7710bc72bb9"
   },
   "outputs": [],
   "source": [
    "# Check lemmatization for the first few queries\n",
    "for query in data[:20\n",
    "                  ]:  # Iterate over the first  preprocessed queries\n",
    "    doc = nlp(query)  # Process the query with SpaCy\n",
    "    print([token.lemma_ for token in doc])  # Print lemmatized words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ezpBggybB9yl",
    "outputId": "9eac852c-2aef-4779-c379-912a7728bdd4"
   },
   "outputs": [],
   "source": [
    "num_clusters = 8\n",
    "\n",
    "# Perform K-Means clustering\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init=10)\n",
    "kmeans.fit(sentence_embeddings)\n",
    "\n",
    "# Add cluster labels to results\n",
    "results = pd.DataFrame({\n",
    "    'Query': data,\n",
    "    'Cluster': kmeans.labels_\n",
    "})\n",
    "\n",
    "# Automate intent labeling using top keywords\n",
    "top_keywords = {}\n",
    "for cluster in range(num_clusters):\n",
    "    cluster_queries = results[results['Cluster'] == cluster]['Query']\n",
    "    words = ' '.join(cluster_queries).split()\n",
    "    top_keywords[cluster] = Counter(words).most_common(5)  # Top 5 keywords\n",
    "\n",
    "# Print top keywords for each cluster\n",
    "for cluster, keywords in top_keywords.items():\n",
    "    print(f\"Cluster {cluster}: {keywords}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "icg2JjYgAqlH"
   },
   "outputs": [],
   "source": [
    "cluster_labels_mapping = {\n",
    "    0: \"--\",\n",
    "    1: \"--\",\n",
    "    2: \"--ν\",\n",
    "    3:\"--\",\n",
    "    4: \"--\",\n",
    "    5:\"--\",\n",
    "    6: \"--\",\n",
    "    7: \"--\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nAn1-xRkO2Rt",
    "outputId": "24f71734-0a93-44db-e8ec-06668f27268a"
   },
   "outputs": [],
   "source": [
    "# Simple CLI for testing\n",
    "def predict_intent(query):\n",
    "\n",
    "    embedding = model.encode([query])\n",
    "    cluster = kmeans.predict(embedding)[0]\n",
    "    return cluster_labels_mapping.get(cluster, 'unknown intent')\n",
    "\n",
    "# Test the CLI\n",
    "while True:\n",
    "    query = input(\"Enter your query (or type 'exit' to quit): \")\n",
    "    if query.lower() == 'exit':\n",
    "        break\n",
    "    intent = predict_intent(query)\n",
    "    print(f\"Predicted Intent: {intent}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EIe7GJpoDGRz",
    "outputId": "c26c4310-0f83-49c0-af6e-73d2ffe987b1"
   },
   "outputs": [],
   "source": [
    "# View all rows of each cluster\n",
    "for cluster in range(num_clusters):\n",
    "    print(f\"Cluster {cluster}: {cluster_labels_mapping.get(cluster, 'Unknown')}\")\n",
    "    cluster_data = results[results['Cluster'] == cluster]\n",
    "    print(cluster_data[['Query']])  # Display only the query column \n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uMkjfVe4DG1T"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
